# 5 - Delete Relaxation Heuristics



## 知识点 & [题目](#题目)

Delete relaxation is a method to relax planning tasks, and thus automatically compute heuristic functions h.

Every h yields good performance only in some domains! (Search reduction vs. computational overhead)

Relaxed world: "What was once true remains true forever."

<img src="images/5/5-1.jpg" alt="5-1" style="zoom:80%;" />

**A Relaxed plan for "TSP" in Australia:**

<img src="images/5/5-2.jpg" alt="5-2" style="zoom:80%;" />

#### **Delete Relaxation & State Dominance**

The delete relaxation is aka ignoring delete lists.

<img src="images/5/5-3.jpg" alt="5-3" style="zoom:80%;" />

<img src="images/5/5-4.jpg" alt="5-4" style="zoom:80%;" />

#### **Greedy Relaxed Planning**

<img src="images/5/5-5.jpg" alt="5-5" style="zoom:80%;" />

<img src="images/5/5-6.jpg" alt="5-6" style="zoom:80%;" />

#### **The optimal delete relaxation heuristic**

<img src="images/5/5-7.jpg" alt="5-7" style="zoom:80%;" />

<img src="images/5/5-8.jpg" alt="5-8" style="zoom:80%;" />

​					**h<sup>+</sup>(TSP) = Minimum Spanning Tree**

​					h<sup>+</sup>(Hanoi) = n, not 2<sup>n</sup>	L5 P16

<img src="images/5/5-9.jpg" alt="5-9" style="zoom:80%;" />

​				**Theorem (Optimal Relaxed Planning is Hard): PlanOpt<sup>+</sup> is NP-complete.**	Proof: L5 P17

<img src="images/5/5-10.jpg" alt="5-10" style="zoom:80%;" />

**Not efficiently computable:**

* (a) approximate h<sup>'*</sup>
* (b) design h<sup>'*</sup> in a way so that it will typically be feasible
* (c) just live with it and hope for the best
  * Many known relaxations (in planning) are efficiently computable, some aren’t. The latter use (a).
  * (b) and (c) are not used anywhere right now.
* The delete relaxation heuristic we want is h<sup>+</sup>. Unfortunately, this is hard to compute so the computational overhead is very likely to be prohibitive. All implemented systems using the delete relaxation approximate h<sup>+</sup> in one or the other way.



#### *<u>The Additive and Max Heuristics</u>*

![5-12](images/5/5-12.jpg)

![5-13](images/5/5-13.jpg)

![5-14](images/5/5-14.jpg)



#### Bellman-Ford for  and h<sup>add</sup>

<img src="images/5/5-15.jpg" alt="5-15" style="zoom:80%;" />

**h<sup>max</sup> in "TSP" in Australia**

![5-16](images/5/5-16.jpg)

**h<sup>add</sup> in "TSP" in Australia**

![5-17](images/5/5-17.jpg)

**h<sup>add</sup> in "Logistics"**

![5-18](images/5/5-18.jpg)

![5-19](images/5/5-19.jpg)



#### Relaxed Plans: Reduce over-counting

<img src="images/5/5-20.jpg" alt="5-20" style="zoom:80%;" />

<img src="images/5/5-21.jpg" alt="5-21" style="zoom:80%;" />

<img src="images/5/5-22.jpg" alt="5-22" style="zoom:80%;" />

<img src="images/5/5-24.jpg" alt="5-24" style="zoom:80%;" />

![5-23](images/5/5-23.jpg)

<img src="images/5/5-25.jpg" alt="5-25" style="zoom:80%;" />

<img src="images/5/5-26.jpg" alt="5-26"  />

![5-27](images/5/5-27.jpg)

![5-28](images/5/5-28.jpg)

![5-29](images/5/5-29.jpg)

![5-30](images/5/5-30.jpg)

* Expanding only helpful actions does not guarantee completeness.
* Other planners use helpful actions as preferred operators, expanding first nodes resulting from helpful actions.



#### Summary

#### <img src="images/5/5-31.jpg" alt="5-31" style="zoom:80%;" />



## 题目

### Quiz

<img src="images/5/5-11.jpg" alt="5-11" style="zoom:80%;" />

<img src="images/5/5-32.jpg" alt="5-32" style="zoom:80%;" />

<img src="images/5/5-33.jpg" alt="5-33" style="zoom:120%;" />

<img src="images/5/5-34.jpg" alt="5-34" style="zoom:120%;" />

